{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "JrrT_PLfvC_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from typing import Any, Tuple, List, Dict"
      ],
      "metadata": {
        "id": "kzIRbl4GvLH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOIdosmKuYpi"
      },
      "outputs": [],
      "source": [
        "def load_image(image_path: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Load an image from disk.\n",
        "    Raises FileNotFoundError if the image cannot be loaded.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Image not found or unable to load: {image_path}\")\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_segmentation_model(model_path: str, device: str = 'cpu') -> Any:\n",
        "    \"\"\"\n",
        "    Load a segmentation model (e.g., Ultralytics YOLO) and move it to the specified device.\n",
        "    \"\"\"\n",
        "    model = YOLO(model_path)\n",
        "    try:\n",
        "        model.to(device)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return model\n",
        "\n",
        "\n",
        "def segment_image(\n",
        "    image: np.ndarray,\n",
        "    model: Any,\n",
        "    object_type: str,\n",
        "    class_mapping: Dict[str, int]\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Perform instance segmentation on the image, returning a binary mask for the specified object type\n",
        "    and a combined foreground mask of all detected objects.\n",
        "    \"\"\"\n",
        "    results = model.predict(image, verbose=False)\n",
        "    h, w = image.shape[:2]\n",
        "    combined_fg = np.zeros((h, w), dtype=np.uint8)\n",
        "    object_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "    target_cls = class_mapping.get(object_type)\n",
        "\n",
        "    for res in results:\n",
        "        if hasattr(res, 'masks') and res.masks is not None:\n",
        "            masks = res.masks.data.cpu().numpy()\n",
        "            classes = res.boxes.cls.cpu().numpy().astype(int)\n",
        "            for m, cls in zip(masks, classes):\n",
        "                if m.shape != (h, w):\n",
        "                    m = cv2.resize(m, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "                mask_bin = (m > 0.5).astype(np.uint8) * 255\n",
        "                combined_fg = cv2.bitwise_or(combined_fg, mask_bin)\n",
        "                if cls == target_cls:\n",
        "                    object_mask = cv2.bitwise_or(object_mask, mask_bin)\n",
        "\n",
        "    bg_mask = cv2.bitwise_not(combined_fg)\n",
        "    return object_mask, bg_mask\n",
        "\n",
        "\n",
        "def get_distance_map(\n",
        "    image_shape: Tuple[int, int],\n",
        "    object_distance_info: Any\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Obtain or construct a per-pixel distance map.\n",
        "    \"\"\"\n",
        "    h, w = image_shape\n",
        "    if isinstance(object_distance_info, np.ndarray):\n",
        "        if object_distance_info.shape != (h, w):\n",
        "            raise ValueError(\"Distance array shape does not match image shape.\")\n",
        "        return object_distance_info.astype(float)\n",
        "    if isinstance(object_distance_info, (float, int)):\n",
        "        return np.full((h, w), float(object_distance_info), dtype=float)\n",
        "    if isinstance(object_distance_info, str):\n",
        "        dm = cv2.imread(object_distance_info, cv2.IMREAD_UNCHANGED)\n",
        "        if dm is None:\n",
        "            raise FileNotFoundError(f\"Depth map not found: {object_distance_info}\")\n",
        "        dm = dm.astype(float)\n",
        "        if dm.max() > 1:\n",
        "            dm = dm / 255.0\n",
        "        return dm\n",
        "    raise TypeError(\"Unsupported object_distance_info type.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## These are important functions that acctually blur the image##\n",
        "\n"
      ],
      "metadata": {
        "id": "p3l0WPAPHyPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sigma_map(\n",
        "    distance_map: np.ndarray,\n",
        "    blur_start: float,\n",
        "    blur_growth_rate: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute a per-pixel sigma map based on distance. No blur if d <= blur_start,\n",
        "    then linear growth beyond.\n",
        "    \"\"\"\n",
        "    sigma_map = np.zeros_like(distance_map, dtype=float)\n",
        "    mask = distance_map > blur_start\n",
        "    sigma_map[mask] = (distance_map[mask] - blur_start) * blur_growth_rate\n",
        "    return sigma_map\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def apply_spatial_gaussian_blur(\n",
        "    image: np.ndarray,\n",
        "    sigma_map: np.ndarray,\n",
        "    sigma_levels: List[float],\n",
        "    ksizes: List[int]\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Approximate spatially varying Gaussian blur by quantizing sigma_map into discrete levels,\n",
        "    blurring the image at each level, and compositing via masks.\n",
        "    \"\"\"\n",
        "    if len(sigma_levels) != len(ksizes):\n",
        "        raise ValueError(\"sigma_levels and ksizes must have the same length.\")\n",
        "    if sigma_levels[0] != 0 or ksizes[0] != 1:\n",
        "        raise ValueError(\"First sigma level must be 0 with kernel size 1.\")\n",
        "\n",
        "    blurred_variants: Dict[float, np.ndarray] = {0.0: image.copy()}\n",
        "    for s, k in zip(sigma_levels[1:], ksizes[1:]):\n",
        "        k_safe = max(1, k if k % 2 == 1 else k + 1)\n",
        "        blurred_variants[s] = cv2.GaussianBlur(image, (k_safe, k_safe), sigmaX=s)\n",
        "\n",
        "    output = image.copy()\n",
        "    for i in range(1, len(sigma_levels)):\n",
        "        prev_s = sigma_levels[i-1]\n",
        "        curr_s = sigma_levels[i]\n",
        "        mask = (sigma_map > prev_s) & (sigma_map <= curr_s)\n",
        "        output = np.where(mask[..., np.newaxis], blurred_variants[curr_s], output)\n",
        "    max_s = sigma_levels[-1]\n",
        "    mask_max = sigma_map > max_s\n",
        "    if np.any(mask_max):\n",
        "        output = np.where(mask_max[..., np.newaxis], blurred_variants[max_s], output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "DYtuSMhsHxDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom color tint for better blur visibility, it is called in the main area\n",
        "\n",
        "def apply_color_tint(\n",
        "    image: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    color: Tuple[int, int, int],\n",
        "    alpha: float = 0.3\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Apply a semi-transparent color tint to the masked regions of the image.\n",
        "    mask: 2D boolean array where True indicates pixels to tint.\n",
        "    color: BGR tuple, alpha: tint strength.\n",
        "    \"\"\"\n",
        "    # 1) Make sure mask is boolean\n",
        "    mask_bool = mask.astype(bool)\n",
        "\n",
        "    # 2) Create an empty overlay and paint only the masked pixels with your tint color\n",
        "    overlay = np.zeros_like(image, dtype=np.uint8)\n",
        "    overlay[mask_bool] = color  # broadcast (h,w,3) ← (3,)\n",
        "\n",
        "    # 3) Blend original + overlay (only the colored bits will actually change)\n",
        "    blended = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)\n",
        "\n",
        "    # 4) Copy the blended (tinted) pixels back onto your original image\n",
        "    output = image.copy()\n",
        "    output[mask_bool] = blended[mask_bool]\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "1EPsCc5cHCaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Distance masks for manaul blur filter effect ##\n",
        "\n",
        "Basically you need to fill an array with the desired distance values, the farther(greater) the distance the more blur. The map must be the same shape as the image."
      ],
      "metadata": {
        "id": "Sufj33UGGVek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_heart_depth_map(\n",
        "    image_shape: Tuple[int, int],\n",
        "    min_depth: float = 0.0,\n",
        "    max_depth: float = 1.0,\n",
        "    heart_scale: float = 5\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generate an artificial depth map with:\n",
        "      - A smaller heart (scaled by `heart_scale`) at constant depth = min_depth\n",
        "      - Everywhere else depth = min_depth + gradient increasing toward the edges,\n",
        "        reaching max_depth at the furthest corners.\n",
        "    \"\"\"\n",
        "    h, w = image_shape\n",
        "\n",
        "    # 1) Build normalized coordinate grid centered at (0,0)\n",
        "    ys = np.linspace(-1.5, 1.5, h)[:, None]\n",
        "    xs = np.linspace(-1.0, 1.0, w)[None, :]\n",
        "\n",
        "    # 2) Shrink coords for the heart mask\n",
        "    xs_h = xs * heart_scale\n",
        "    ys_h = ys * heart_scale\n",
        "\n",
        "    # 3) Implicit heart equation (inside <=1)\n",
        "    row_mask = (\n",
        "        xs_h**2\n",
        "        + (5.0/4.0 * ys_h - np.sqrt(np.abs(xs_h)))**2\n",
        "        <= 1.0\n",
        "    )\n",
        "\n",
        "    # 4) Compute radial distance from center, normalized to [0, 1]\n",
        "    #    max possible radius is at a corner: sqrt(1^2 + 1.5^2)\n",
        "    max_radius = np.sqrt(1.0**2 + 1.5**2)\n",
        "    radius = np.sqrt(xs**2 + ys**2)\n",
        "    norm_radius = np.clip(radius / max_radius, 0.0, 1.0)\n",
        "\n",
        "    # 5) Build the gradient: at center = min_depth, at edges = max_depth\n",
        "    gradient = min_depth + norm_radius * (max_depth - min_depth)\n",
        "\n",
        "    # 6) Combine: heart = flat min_depth; outside = gradient\n",
        "    depth_map = np.where(row_mask, min_depth, gradient).astype(float)\n",
        "    return depth_map\n",
        "\n",
        "def generate_constant_rectangle_depth_map(\n",
        "    image_shape: Tuple[int, int],\n",
        "    min_depth: float = 0.0,\n",
        "    max_depth: float = 50.0,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generate a depth map with three horizontal bands:\n",
        "      - Top third:      depth = max_depth\n",
        "      - Middle third:   depth = max_depth / 2\n",
        "      - Bottom third:   depth = min_depth\n",
        "    \"\"\"\n",
        "    h, w = image_shape\n",
        "    # compute band boundaries (integer row indices)\n",
        "    top_end = h // 3\n",
        "    mid_end = (2 * h) // 3\n",
        "\n",
        "    # initialize all to zero (or any placeholder)\n",
        "    depth_map = np.empty((h, w), dtype=float)\n",
        "\n",
        "    # fill each band\n",
        "    depth_map[:top_end, :] = max_depth\n",
        "    depth_map[top_end:mid_end, :] = max_depth / 10.0\n",
        "    depth_map[mid_end:, :] = min_depth\n",
        "\n",
        "    return depth_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "PYYLZrmIGN2v",
        "outputId": "04bba942-e92c-4956-adac-ae73cbad34a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Tuple' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f4dccc29a512>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m def generate_heart_depth_map(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage_shape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmin_depth\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mheart_scale\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tuple' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Function Area ##\n",
        "\n",
        "Edit the arguments for the blur function"
      ],
      "metadata": {
        "id": "FJHjDHxNG4jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(\n",
        "    image_path: str,\n",
        "    object_distance_info: Any,\n",
        "    object_type: str,\n",
        "    config: Dict[str, Any],\n",
        "    use_synthmap: bool = True\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Orchestrate the spatially varying blur pipeline.\n",
        "    \"\"\"\n",
        "    img = load_image(image_path)\n",
        "    # Depth map selection\n",
        "    if use_synthmap:\n",
        "        #base_dist = generate_synthmap_depth_map(img.shape[:2])\n",
        "        base_dist = generate_constant_rectangle_depth_map(img.shape[:2])\n",
        "    else:\n",
        "        base_dist = get_distance_map(img.shape[:2], object_distance_info)\n",
        "\n",
        "    # Segmentation\n",
        "    model = load_segmentation_model(config['model_path'], config.get('device', 'cpu'))\n",
        "    object_mask, bg_mask = segment_image(img, model, object_type, config['class_mapping'])\n",
        "\n",
        "    # Blur sigma maps\n",
        "    sigma_base = calculate_sigma_map(base_dist, config['blur_start'], config['blur_growth_rate'])\n",
        "    full_blur = apply_spatial_gaussian_blur(img, sigma_base, config['sigma_levels'], config['ksizes'])\n",
        "    background_blurred = np.where(bg_mask[..., np.newaxis].astype(bool), full_blur, img)\n",
        "\n",
        "    sigma_obj = calculate_sigma_map(\n",
        "        base_dist,\n",
        "        config['blur_start'] * config.get('blur_start_height_multiplier', 1.0),\n",
        "        config['blur_growth_rate']\n",
        "    )\n",
        "    object_blur = apply_spatial_gaussian_blur(img, sigma_obj, config['sigma_levels'], config['ksizes'])\n",
        "    final = np.where(object_mask[..., np.newaxis].astype(bool), object_blur, background_blurred)\n",
        "\n",
        "\n",
        "    # Optional color tint for all blurred pixels\n",
        "    if 'blur_color' in config:\n",
        "    # 1) get mask from sigma, not pixel-diff\n",
        "      blur_mask = sigma_base > 0\n",
        "      color = tuple(config['blur_color'])\n",
        "      alpha = config.get('blur_color_alpha', 0.3)\n",
        "      final = apply_color_tint(final, blur_mask, color, alpha)\n",
        "    cv2.imwrite(config['output_path'], final)\n",
        "    print(f\"Output saved to {config['output_path']}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import argparse, json, os # import os\n",
        "\n",
        "    # Instead of using argparse, define arguments directly or use a configuration file\n",
        "    class Args:\n",
        "        def __init__(self, image, depth, type, config, use_synthmap):\n",
        "            self.image = image\n",
        "            self.depth = depth\n",
        "            self.type = type\n",
        "            self.config = config\n",
        "            self.use_synthmap = use_synthmap\n",
        "\n",
        "    # Provide values for the arguments\n",
        "    args = Args(\n",
        "        image='gridTest.png',  # Update with your image path\n",
        "        depth='path/to/your/depth_map.png',  # Update with your depth map if not using --use-heart\n",
        "        type='person',  # Update with your desired object type\n",
        "        config='config.json',  # Update with your config file if needed\n",
        "        use_sythmap=True  # Set to True to use the artificial heart depth map\n",
        "    )\n",
        "\n",
        "    # Configuration file handling -- Generates a config file for future use, edit that file or delete and edit this section for changes\n",
        "    if not os.path.exists(args.config):\n",
        "        default_config = {\n",
        "            \"model_path\": \"yolov8n-seg.pt\",\n",
        "            \"device\": \"cpu\",\n",
        "            \"class_mapping\": {\"person\": 0},\n",
        "            \"blur_start\": 0.2,\n",
        "            \"blur_growth_rate\": 0.5,\n",
        "            \"blur_start_height_multiplier\": 1.2,\n",
        "            \"sigma_levels\": [0, 5, 15, 30],\n",
        "            \"ksizes\": [1, 11, 31, 61],\n",
        "            \"output_path\": \"output_image.png\",\n",
        "            \"blur_color\": \"0,0,255\",\n",
        "            \"blur_color_alpha\": 0.3\n",
        "        }\n",
        "        with open(args.config, 'w') as f:\n",
        "            json.dump(default_config, f, indent=4)\n",
        "        print(f\"Created default config file: {args.config}\")\n",
        "\n",
        "    cfg = json.load(open(args.config))\n",
        "    print(\"Config I’m actually using:\\n\", cfg)\n",
        "    # Parse blur color argument (if provided in the configuration file)\n",
        "    if 'blur_color' in cfg:\n",
        "        print(\"Blur found\")\n",
        "        try:\n",
        "            cfg['blur_color'] = [int(c) for c in cfg['blur_color'].split(',')]\n",
        "        except Exception:\n",
        "            raise ValueError(\"blur_color in config file must be in format B,G,R with integer values\")\n",
        "\n",
        "    main(args.image, args.depth, args.type, cfg, use_synthmap=args.use_synthmap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "DIZIPspbE3_n",
        "outputId": "e65c0eec-0829-4997-80d5-53ba4ff8b14f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Any' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-290199e46f1a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m def main(\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mobject_distance_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mobject_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Any' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1pBZbno_GPyu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}